{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mcmc_nuts_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJB3Qnb61KyYuw+PZFeWIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weldlabucsb/mcmc/blob/master/mcmc_nuts_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbDSkPEvnzQi",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1uhEQp4-4nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Goal of this notebook is to create some simple code that can take a 1d array which we will suppose we have, i.e. it will be one of the inputs\n",
        "#and we will take it and compare it to simulated data.\n",
        "\n",
        "## Imports:\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from scipy.integrate import odeint\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import solve_ivp\n",
        "from multiprocessing import Process, Queue\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "class _TFColor(object):\n",
        "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
        "    red = '#F15854'\n",
        "    blue = '#5DA5DA'\n",
        "    orange = '#FAA43A'\n",
        "    green = '#60BD68'\n",
        "    pink = '#F17CB0'\n",
        "    brown = '#B2912F'\n",
        "    purple = '#B276B2'\n",
        "    yellow = '#DECF3F'\n",
        "    gray = '#4D4D4D'\n",
        "    def __getitem__(self, i):\n",
        "        return [\n",
        "            self.red,\n",
        "            self.orange,\n",
        "            self.green,\n",
        "            self.blue,\n",
        "            self.pink,\n",
        "            self.brown,\n",
        "            self.purple,\n",
        "            self.yellow,\n",
        "            self.gray,\n",
        "        ][i % 9]\n",
        "TFColor = _TFColor()\n",
        "\n",
        "tfd = tfp.distributions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrS6QGPbpVLN",
        "colab_type": "text"
      },
      "source": [
        "# Global Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXvqbNSppYit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of \"pixels\" on the direction\n",
        "N = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTaSxYXBoa9D",
        "colab_type": "text"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty8OTXZYDhlt",
        "colab_type": "text"
      },
      "source": [
        "We will take some data and turn it a 1d array with the data along a given direction.\n",
        "\n",
        "The idea is that the data is a 2d matrix, we will interpolate it to get a function OD(x, y) that will provide the optical density at pixels x,y. We want to be able to slice it, so that we give a direction like \\[0,1] or \\[1,1] and with N bins. Each bin would represent a pixel. \n",
        "\n",
        "We have used the DataManager made by Peter to get a CSV file that I will use for this run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vTRmA0rls47",
        "colab_type": "text"
      },
      "source": [
        "Load the optical density (could add some kind of interworking with matlab maybe).\n",
        "\n",
        "All of the od < 0 should be equal to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpFe4lyrRv9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80bebc8c-db1a-4785-bcb1-5724daa609dd"
      },
      "source": [
        "#load csv file:\n",
        "od = np.loadtxt(r\"/content/drive/My Drive/Colab Notebooks/Weld Lab/data/optical density run 18.csv\", delimiter=\",\", encoding='utf-8-sig').T\n",
        "od[od < 0] = 0 #isn't this so easy with numpy?? How do you even do the same on matlab? Is it as easy, maybe?\n",
        "od.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 390)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgLoa-I4Fcqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import scipy:\n",
        "from scipy.interpolate import RectBivariateSpline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzW2fla2pz4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Interpolation of OD\n",
        "X = range(od.shape[0])\n",
        "Y = range(od.shape[1])\n",
        "optical_density = RectBivariateSpline(X, Y, od)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DTsv2PZojGg",
        "colab_type": "text"
      },
      "source": [
        "## Helper function to cut through the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgo_RsAEqrUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this function will provide an array of points, so X, and Y where X[i], Y[i]\n",
        "#are places where to evaluate this the function along a given direction.\n",
        "def points(start, end, Nx, Ny, N):\n",
        "  x1 = start[0]\n",
        "  y1 = start[1]\n",
        "  x2, y2 = end\n",
        "  line = lambda x: (y2-y1)/(x2-x1)*(x-x1)+y1\n",
        "  \n",
        "  \n",
        "  xinit = (x2*y1-x1*y2)/(y1-y2)\n",
        "  xfinal = (Ny*(x1-x2)-x1*y2+x2*y1)/(y1-y2)\n",
        "  print(f\"xinit is {xinit:.2f}, xfinal is {xfinal:.2f}.\")\n",
        "  if xinit<0:\n",
        "    xinit = 0\n",
        "  elif xinit > Nx:\n",
        "    xinit = Nx\n",
        "  if xfinal > Nx:\n",
        "    xfinal = Nx\n",
        "  elif xfinal < 0:\n",
        "    xfinal = 0\n",
        "  \n",
        "  X = np.linspace(xinit, xfinal, N)\n",
        "  Y = line(X)\n",
        "  return (X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MoIwKHpcqwMg"
      },
      "source": [
        "## Helper function to cut through the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xpFQDSqzQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y = points((15,196),(25,189), od.shape[0], od.shape[1], int(N))\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(X, Y)\n",
        "plt.xlim(0, od.shape[0])\n",
        "plt.ylim(0, od.shape[1])\n",
        "plt.figure(figsize=(5,5))\n",
        "Slice = optical_density(X, Y, grid=False)\n",
        "plt.plot(Slice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy2DvQe6q95m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize the slice: (add option to normalise with true dx later)\n",
        "from scipy.integrate import trapz\n",
        "Slice = Slice/trapz(Slice)\n",
        "#make sure there's no negative numbers:\n",
        "Slice[Slice < 0] = 0\n",
        "plt.plot(Slice)\n",
        "trapz(Slice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDgXlFlwmUTH",
        "colab_type": "text"
      },
      "source": [
        "# Markov Chain Monte Carlo Set Up\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA1duz8go0oH",
        "colab_type": "text"
      },
      "source": [
        "## Initial Step Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFJZsSs0vEig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.cast(tf.constant(range(N)), dtype=tf.float32)\n",
        "print(X)\n",
        "sigma = 8.\n",
        "def gaussian_rates(sigma, mu, w):\n",
        "  # Xmod = tf.transpose(X*tf.ones(( mu.shape[0], X.shape[0])))\n",
        "  # print(Xmod)\n",
        "  # Mumod = mu*tf.ones((X.shape[0], mu.shape[0]))\n",
        "  # print(Mumod)\n",
        "  # I0 =  Xmod - Mumod\n",
        "  # print(I0)\n",
        "  # I1 = -1.*(tf.pow(I0, 2.)/sigma)\n",
        "  return w*tf.exp(  -1.*tf.pow(tf.transpose(X*tf.ones(( mu.shape[0], X.shape[0])))-\n",
        "                    mu*tf.ones((X.shape[0], mu.shape[0])), 2.)/sigma )\n",
        "\n",
        "def sim_od_dist(sigma, mu, w):\n",
        "  rate = w*tf.exp(-(tf.pow(X-mu, 2.)/sigma))\n",
        "  rate = rate.numpy()\n",
        "  rate[rate < 1e-8] = 1e-10\n",
        "  #let's try 3 poisson distributions centered at different places.\n",
        "\n",
        "  # print(\"rate \", rate)\n",
        "  return tfd.Independent(tfd.Poisson(rate=tf.convert_to_tensor(rate, dtype=tf.float32)), reinterpreted_batch_ndims=1)\n",
        "  # return tfd.Independent(tfd.Normal(loc=w*tf.exp(-(tf.pow(X-mu, 2.)/sigma)), scale=2.), reinterpreted_batch_ndims=1)\n",
        "def sim_od_multiple_dist(sigma, mu, w):\n",
        "  # rates = gaussian_rates(sigma, mu, w)\n",
        "  return tfd.Independent(tfd.Normal(loc=tf.reduce_sum(gaussian_rates(sigma,\n",
        "                                                                     mu, w),\n",
        "                                                      axis=1),\n",
        "                                    scale=tf.ones((int(N),))*0.2), reinterpreted_batch_ndims=1)\n",
        "\n",
        "\n",
        "\n",
        "dists = [\n",
        "         #w\n",
        "         tfd.Uniform(low=0.0, high=10000.0),\n",
        "         #mu\n",
        "         tfd.Normal(loc=50., scale=8.),\n",
        "         #sigma\n",
        "         tfd.Normal(loc=20., scale=10.),\n",
        "         #total atoms\n",
        "         tfd.Normal(loc=10000., scale=50.),\n",
        "         lambda atoms, sigma, mu, w: sim_od_dist(sigma, mu, w)\n",
        "]\n",
        "def generate_multiple_dists(n: int):\n",
        "  return [\n",
        "         #w\n",
        "         tfd.Independent(tfd.Uniform(low=[0.0]*n, high=[10000.]*n),reinterpreted_batch_ndims=1),\n",
        "         #mu\n",
        "         tfd.Independent(tfd.Normal(loc=[80.]*n, scale=[50.]*n), reinterpreted_batch_ndims=1),\n",
        "         #sigma\n",
        "         tfd.Independent(tfd.Normal(loc=[50.]*n, scale=[5.]*n), reinterpreted_batch_ndims=1),\n",
        "         #total atoms\n",
        "         tfd.Normal(loc=1000., scale=80.),\n",
        "         lambda atoms, sigma, mu, w: sim_od_multiple_dist(sigma, mu, w)\n",
        "        ]\n",
        "\n",
        "\n",
        "od_dist = tfd.JointDistributionSequential(dists)\n",
        "od_multiple_dist = tfd.JointDistributionSequential(generate_multiple_dists(3))\n",
        "print(od_multiple_dist.resolve_graph())\n",
        "s = od_multiple_dist.sample(1)\n",
        "print(\"sample \", s)\n",
        "od_multiple_dist.log_prob_parts(s)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fhYxZ2yrdZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_log_prob_tr(*init_state):\n",
        "  try:\n",
        "    #print(\"init st = \", init_state, \"\\n len init\", len(init_state))\n",
        "    atoms = init_state[3]\n",
        "    inp = list(init_state)+[Slice*atoms]\n",
        "    return od_dist.log_prob(inp)\n",
        "    #print(\"inp \", inp, \"\\n\", len(inp))\n",
        "  except Exception as e:\n",
        "    # print(e)\n",
        "    atoms = init_state[0][3]\n",
        "    # print(atoms)\n",
        "    inp = list(init_state[0])+[Slice*atoms]\n",
        "    # print(inp)\n",
        "    try:\n",
        "      return od_dist.log_prob(inp)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print(init_state)\n",
        "      exit()\n",
        "\n",
        "def target_log_prob_multiple_normals(*init_state):\n",
        "  try:\n",
        "    # print(\"init st = \", init_state, \"\\n len init\", len(init_state))\n",
        "    atoms = init_state[3]\n",
        "    inp = list(init_state)+[Slice*atoms]\n",
        "    return od_multiple_dist.log_prob(inp)\n",
        "    #print(\"inp \", inp, \"\\n\", len(inp))\n",
        "  except Exception as e:\n",
        "    # print(e)\n",
        "    atoms = init_state[0][3]\n",
        "    # print(atoms)\n",
        "    inp = list(init_state[0])+[Slice*atoms]\n",
        "    # print(inp)\n",
        "    try:\n",
        "      return od_multiple_dist.log_prob(inp)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print(init_state)\n",
        "      exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQTjumTnrhYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creation of the distribution used:\n",
        "# dist = closed_joint_dist_gen(int(N)) #N is the number of pixels in the slice, set globally\n",
        "# dist = \n",
        "#how many chains should we use?\n",
        "chains = 1\n",
        "#sample it:\n",
        "# start = dist.sample()\n",
        "step_size = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCk2UKeQr0tu",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Bijectors\n",
        "# Since HMC operates over unconstrained space, we need to transform the\n",
        "# samples so they live in real-space.\n",
        "# unconstraining_bijectors = [\n",
        "#     tfp.bijectors.Exp(),       # Maps a positive real to R. for x_tail\n",
        "#     tfp.bijectors.Exp(), # for lambda center\n",
        "#     tfp.bijectors.Exp(), # for lambda left\n",
        "#     tfp.bijectors.Exp(), # for lambda right\n",
        "#     tfp.bijectors.Exp(), # for sigma center\n",
        "#     tfp.bijectors.Exp(), # for sigma left\n",
        "#     tfp.bijectors.Exp(), # for sigma right\n",
        "#     tfp.bijectors.Exp(), # for sigmai\n",
        "#     tfp.bijectors.Exp(), # for amplitude\n",
        "#     tfp.bijectors.Sigmoid(), #for mix center\n",
        "#     tfp.bijectors.Sigmoid() #for mix left\n",
        "#     # tfp.bijectors.Sigmoid(),       # Maps [0,1] to R. for gamma\n",
        "#     # tfp.bijectors.Sigmoid(),   # Maps [0,1] to R. for delta\n",
        "#     # tfp.bijectors.Exp(),        # Maps a positive real to R. for I0\n",
        "#     # tfp.bijectors.Exp(), # Maps a positive real to R. for R0\n",
        "#     # tfp.bijectors.Sigmoid() # Maps [0,1] to R. for care\n",
        "# ]\n",
        "unconstraining_bijectors = [\n",
        "    tfp.bijectors.Exp(),       # Maps a positive real to R. for x_tail\n",
        "    tfp.bijectors.Exp(), # for mu\n",
        "    tfp.bijectors.Exp(), # for sigma\n",
        "    tfp.bijectors.Exp() # for atom number\n",
        "    # tfp.bijectors.Exp(), # for lambda right\n",
        "    # tfp.bijectors.Exp(), # for sigma center\n",
        "    # tfp.bijectors.Exp(), # for sigma left\n",
        "    # tfp.bijectors.Exp(), # for sigma right\n",
        "    # tfp.bijectors.Exp(), # for sigmai\n",
        "    # tfp.bijectors.Exp(), # for amplitude\n",
        "    # tfp.bijectors.Sigmoid(), #for mix center\n",
        "    # tfp.bijectors.Sigmoid() #for mix left\n",
        "    # tfp.bijectors.Sigmoid(),       # Maps [0,1] to R. for gamma\n",
        "    # tfp.bijectors.Sigmoid(),   # Maps [0,1] to R. for delta\n",
        "    # tfp.bijectors.Exp(),        # Maps a positive real to R. for I0\n",
        "    # tfp.bijectors.Exp(), # Maps a positive real to R. for R0\n",
        "    # tfp.bijectors.Sigmoid() # Maps [0,1] to R. for care\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lzf3dO6r5Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Starting MCMC Code\n",
        "from google.colab import output\n",
        "chains = 1\n",
        "local_runtime = False #@param {type:\"boolean\"}\n",
        "# wrap the mcmc sampling call in a @tf.function to speed it up\n",
        "#@tf.function(autograph=False)\n",
        "calls = 0\n",
        "def graph_sample_chain(*args, **kwargs):\n",
        "  print(\"current = \",kwargs[\"current_state\"])\n",
        "  start_time = time.time()\n",
        "  out = tfp.mcmc.sample_chain(*args, **kwargs)\n",
        "  print(f\"It took: {(time.time()-start_time)/60} min\")\n",
        "  return out\n",
        "def trace_fn(_, pkr):\n",
        "    return (\n",
        "        #pkr.inner_results.inner_results.target_log_prob,\n",
        "        pkr.inner_results.inner_results.leapfrogs_taken,\n",
        "        pkr.inner_results.inner_results.has_divergence,\n",
        "        pkr.inner_results.inner_results.energy,\n",
        "        pkr.inner_results.inner_results.log_accept_ratio\n",
        "           )\n",
        "# r0, gamma, delta, I0, rho, _ = mdl_ols_batch.sample(nchain)\n",
        "# init_state = [b0, b1]\n",
        "# # step_size = [tf.cast(i, dtype=dtype) for i in [.1, .1]]\n",
        "# target_log_prob_fn = lambda *init_state: mdl_ols_batch.log_prob(\n",
        "#     list(init_state) + [Y_np])\n",
        "num_burnin_steps = 10000\n",
        "num_results = 5000\n",
        "\n",
        "\n",
        "\n",
        "print(step_size)\n",
        "kernel=tfp.mcmc.TransformedTransitionKernel(\n",
        "        inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
        "            target_log_prob_fn=target_log_prob_multiple_normals,\n",
        "            num_leapfrog_steps=2,\n",
        "            step_size=step_size,\n",
        "            state_gradients_are_stopped=False),\n",
        "        bijector=unconstraining_bijectors)\n",
        "\n",
        "kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
        "    inner_kernel=kernel, num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
        "\n",
        "#kernel.bootstrap_results(init_state)\n",
        "\n",
        "# # Sample from the chain.\n",
        "# [\n",
        "#     r0_samples,\n",
        "#     gamma_samples,\n",
        "#     delta_samples,\n",
        "#     I0_samples,\n",
        "#     posterior_care,\n",
        "# ],\n",
        "kernel_results = graph_sample_chain(\n",
        "    num_results=num_results,\n",
        "    num_burnin_steps=num_burnin_steps,\n",
        "    current_state=init, #put init in here if you want to start from init\n",
        "    #previous_kernel_results=kernel.bootstrap_results(initial_chain_state),\n",
        "    kernel = kernel, parallel_iterations=chains)\n",
        "#save the kernel_results to drive:\n",
        "[w_samples, mu_samples, sigma_samples, atom_samples], extra = kernel_results\n",
        "# [xtail_samples, lambdac_samples, lambdal_samples, lambdar_samples, sigmac_samples, sigmal_samples, sigmar_samples, sigmai_samples, amplitude_samples, mixc_samples, mixl_samples], extra = kernel_results\n",
        "#save data as plain npz files:\n",
        "base = r\"Desktop/covid19/\" if local_runtime else r\"/content/drive/My Drive/Colab Notebooks/Weld Lab/data/\"\n",
        "output_path = base + f\"out/output_run18_{time.strftime('%Y-%m-%d-%H:%M %Z', time.localtime())}.npz\"\n",
        "np.savez(output_path, w_samples, mu_samples, sigma_samples, atom_samples)# xtail_samples, lambdac_samples, lambdal_samples, lambdar_samples, sigmac_samples, sigmal_samples, sigmar_samples, sigmai_samples, amplitude_samples, mixc_samples, mixl_samples)\n",
        "\n",
        "# notify.send(\"Finished!\")\n",
        "#np.savez(\"/content/drive/My Drive/Colab Notebooks/out/output_acceptance.npz\", tf.cast(extra.inner_results.inner_results.is_accepted,dtype=tf.float32)).numpy(), extra.inner_results.inner_results.accepted_results.step_size[-100:])\n",
        "# tau_samples = tf.floor(posterior_care * tf.cast(tf.size(cases),dtype=tf.float32))\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w92_LnY-sB1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Calculate Acceptance Rate\n",
        "print(\"acceptance rate: {}\".format(\n",
        "    tf.reduce_mean(tf.cast(extra.inner_results.inner_results.is_accepted,dtype=tf.float32))))\n",
        "print(\"final step size: {}\".format(\n",
        "    tf.reduce_mean(extra.inner_results.inner_results.accepted_results.step_size[-100:])))\n",
        "# extra\n",
        "# step_size = [o[-1] for o in extra.inner_results.inner_results.accepted_results.step_size]\n",
        "step_size =  tf.reduce_mean(extra.inner_results.inner_results.accepted_results.step_size[-100:])\n",
        "tf.reduce_mean(extra.inner_results.inner_results.accepted_results.target_log_prob, axis=0)\n",
        "# step_size = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}